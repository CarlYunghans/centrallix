Title:	    IndexFile.txt - Indexed file object design specification.
Author:	    Greg Beeley (GRB)
Date:	    October 11th, 1999
===============================================================================


OVERVIEW...

    The indexfile objectsystem driver provides an interface to a 'true' 
    database file format, based on a B-tree type of structure and page cache
    mechanism.  This type of database table object is used for the high-level
    sort mechanism in MultiQuery, as well as for other partial query results
    (such as union distinct), and for indexes created on datafile objects
    using the objdrv_datafile objectsystem driver.  These database files can
    of course also be used independently for efficient data storage local
    to LightServer (as opposed to storage in an enterprise-level RDBMS like
    Sybase).

    Update:  The indexing structure in the indexed file will now follow a
    B+-tree structure instead of a B-tree structure.  The reason for this is
    that the concurrency issues with a B-tree became quite unmanageable very
    rapidly, with some processes having to traverse up the tree and some
    having to traverse down the tree, causing possible deadlocks in the middle
    of such traversals.  Though the B+tree doesn't solve all of these problems,
    it does help with some of them.  The file format structure itself need not
    change as a result of this modification.

    Another optimization will relate to key storage.  Compression will be
    available on concatenated primary keys; if a key value in a page is left
    null, then that key value is the same as the previous key value for that
    field in the page.  This optimization makes keys variable-length and thus
    disables binary search on the keys in a page, forcing the search to always
    proceed linearly, which can be a performance penalty, especially if key
    sizes are small.  But for small key sizes that use only one field, the
    compression is automatically disabled anyhow.


FILE FORMAT DESIGN...

    The indexfile file format is the most critical component of the design of
    this module.  The file will be subdivided into the following major 
    components and subcomponents:

        1.  File Header

	    -   First, header magic number 0x7c543219 int32, at offset 0.
	    a.	Header byte count (int32), at offset 4.
	    b.	Header page list (subject to maximum; int32's)
	    c.	Table-wide flags (int32)
	    d.  Root page id (int32)
	    e.  First data page id (int 32)
	    f.  Last data page id (int32)
	    g.	Name (asciz)
	    h.	Annotation string (asciz)
	    i.  Row annotation expression (asciz)
	    j.	Column list and column properties

		- number of columns (int8), then for each, aligned at 4-bytes...
		- column descriptor length (int32)
		- column flags (is nullable, etc; int32)
		- column length (e.g., max string length; int32)
		- column length divisor (e.g., # of lines for multiline; int32)
		- column style indicators (int32)
		- column data type (DATA_T_xxx; int8)
		- column key id (if primary key; int8; 0=no, 1-x=yes)
		- column group id (int8)
	        - column name (asciz)
		- column constraint expression (asciz)
		- column default expression (asciz)
		- column minimum value expression (asciz)
		- column maximum value expression (asciz)
		- column codelist enumeration query (asciz)
		- column presentation format (asciz)
		- column group name (asciz)
		- column description (asciz)

	    k.	Allocation group list and summaries... 4-aligned...

	        - Start page id for allocation group header, 0 if unallocated (int32)
		- Free pages in allocation group (int32)

	    l.  Global modification id (int64), 4-aligned
	    m.  Identity value id (int64)
	    n.  Key length, if fixed length (int16)
	    o.  Data length, if fixed length (int16)

        2.  Allocation Group Header
	
	    a.	Total number of pages (int32)
	    b.	Total number of free pages (int32)
	    c.	Page allocation map (bytemap, not bitmap)

	        - 0xFF = unallocated page (never has been allocated).
		- 0xFE = deallocated page (was previously allocated).
		- 0x00 = allocated root index/data page.
		- 0x01 = allocated file header page.
		- 0x10 - 0x1F = allocated index page, larger value means fuller page.
		- 0x20 - 0x2F = allocated data page, larger value means fuller page.
		- 0x30 - 0x3F = allocated BLOB page; larger value means fuller page.
		- 0x40 - 0x4F = allocated transaction log page.

        3.  Data Page

	    a.	Page ID (0 if free; int32).
	    b.  Page modification ID (int64).
	    c.	Free Space count (int32).
	    d.	Data Row count (int32).
	    e.	Page Pointer count (int32).
	    f.	Page Pointers (int32 each).

	        - First page ptr is for parent.
		- Second page ptr is for next page.
		- Third page ptr is for prev page.
		- 4th and up are for 0th through nth child ptrs.

	    g.  Data Row offsets (int32 each).
	    h.	Data Rows.

		- Row modification id (int64), then for each column...
	        - Column id (8bit)
		- Column data length (16bit)
		- Column data
		* Key columns must be listed first in the row, in order, 
		  for performance reasons.
		* If Key listed second time, primary key changed; follow
		  link to new primary key (rec f1 f2 f1 f2, second f1 f2
		  is redirect)
		* Row must be 4-byte aligned.  This makes data_length an
		  unaligned field.  

	4.  Column data in a data page
	    
	    a.  Integer data - int32
	    b.  String data - raw string, with zero terminator.
	    c.  DateTime data - raw datetime image from DateTime structure
	    d.  Money data - int32/int16, directly from MoneyType structure.
	    e.  Double data - 8-byte floating point value.
	    
	    **  Money and DateTime data must be 4-byte aligned; pad with
	        zeros before the money/datetime data structure to align
		it.  Data length should include the null padding.

	5.  Table-wide flags...

	    a.  Flag to control the use of OS level page locking (lockf/etc)
	    b.  Flag to control the use of a transaction log
	    c.  Use artificial identity for primary key (pair of 32-bit Int)
	    d.  Key is fixed length
	    e.  Data is fixed length
	    f.  Use B+ tree style algorithms.
	    g.  Use B* tree style algorithms for page splits.
	    h.  Use primary key compression on concat keys.
	    i.  Key is not unique (not currently supported!)
	    j.  Column data length only on strings (not currently supported)


HIGH-LEVEL FUNCTIONAL SPECIFICATION...

    This section describes the high-level functionality within the index-file
    driver, such as row lookup, iteration, update, delete, and insert.

	1.  Lookup by key

	2.  Lookup by arbitrary fields

	3.  Iteration through all records

	4.  Updating a row

	5.  Deleting a row

	6.  Inserting a new row


LOW-LEVEL FUNCTIONAL SPECIFICATION...

    This section describes the internal support routines necessary to make the
    higher level routines simple and functional.

        1.  Scan a page for matching key value:

	    a.  Find the data row start offset.
	    b.  For each data row, in sequence, compare with search key.
	    c.  If == row found, return it.
	    d.  If > row found on row <n>, go to pointer <n> to next page.
	    e.  If end of rows, go to pointer <n+1> to next page, if any.
	    f.  Otherwise, not found.

	2.  Find a row matching a given key:

	    a.  Scan the top page for a matching value
	    b.  If proceeding to a next page, scan it as well in the same way.

	3.  Iterate through all rows, in clustered sequence:

	    a.  Go to the top-level page.
	    b.  Start with the first row in the given page.
	    c.  Iterate row-1, pointer-1, row-2, pointer-2 ... row-n
	    d.  Handle a row by returning it.
	    e.  Handle a pointer by descending to the next lower page and
	        scanning it in this same way.
	    f.  If the page has no pointers (leaf page), just do row-1, row-2,
	        etc.
	    g.  When done with a page, return to handling the page above it.
	    h.  When done with the top page, iteration is finished.

	4.  Find row(s) matching the *head* of a key value.

	    a.  Do procedure to find a row matching an exact key, but just
	        compare the key head value.
	    b.  Keep going when a key is found, to return multiple results.
	    c.  Stop when end of rows reached, or on a row > than the key.
	    d.  On encountering a pointer whose previous row is <= the search
	        key and whose next row is >= the search key, search the page
		pointed to by the pointer.

	5.  Find row(s) matching abstract field names

	    a.  Iterate through all rows according to (3).
	    b.  For each row, compare against the abstract field values.

	6.  Sort in reverse order of key value or head-of-key value

	    a.  Iterate as in (1) or (4), but start at the end of data
	        pages instead of the front.

	7.  Sort by abstract fields

	    a.  Allow the OSML to do the sorting, and don't set the fully 
	        sorted result set flag.

    Problem Solving:

        1.  How to resume a search after returning one row, and the data
	    has been modified in the process:

	    a.  When returning a row, keep a record of its name/prikey in the
	        search query structure.
	    b.  Keep a modification-id in the global node structure for the
	        indexfile.
	    c.  Keep the modification-id of the last time the search looked at
	        the data in the search query structure.
	    d.  When fetching the next row from a search, first check to see 
	        if the data changed.  If so, re-traverse the tree to start at
		that key, otherwise start at the position in the page where the 
		search left off (more efficient).

	2.  How to keep critical data from being modified during a search 
	    iteration

	    a.  Keep page-level locking in memory.
	    b.  Keep pages locked from current page being examined up-branch to 
	        the root.
	    c.  Lock a page before modifying that page.

	3.  How to keep consistency between an open object and its position and
	    data layout within the pages of the database, and still make it 
	    somewhat efficient.

	    a.  Keep the modification-id for that row and page
	    b.  When going back to the page for data, check the stored mod id
	        with the page/row's modification id.  If the id changed, re-
		check the data and page reference.

	4.  How to roll-back a transaction or operation.

	    a.  Keep a transaction log, if necessary, either in a separate 
	        object, or as a page-chain in the same file.  Writes to the
		log should be flushed to disk as soon as the operation is done.
	    b.  On rollback, scan back through the log and reverse all items
	        done with that modifcation id sequence.
	    c.  On startup after a crash, scan the log for items to re-do or
	        undo.  Compare with page/row modification id's to check their
		status.
	    d.  This need for transaction rollback is not mandatory at the
	        beginning.

	5.  Protecting a page split or combine during insert, update, and
	    delete

	    a.  Make sure that all pages from the leaf to the root along the
	        branch are locked during the update/insert/delete, since a read
		scan will lock from top-down as well.
	    b.  This will be normal during a scan-driven update/delete.

	6.  Page locking on the file header and allocation bitmaps

	    a.  The process having the root node locked has access to the file
	        header and bitmaps for modification purposes.

	7.  Concurrency in read/write operations

	    a.  After a row has been opened read/write, its page is locked and
	        cannot be further modified.  

-------------------------------------------------------------------------------
